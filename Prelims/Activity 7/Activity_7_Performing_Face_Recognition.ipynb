{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj9Q5rZAFAlM"
      },
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 313\n",
        "Code Title: |  Advanced Machine Learning and Deep Learning\n",
        "1st Semester | AY 2024-2025\n",
        "<hr> | <hr>\n",
        "<u>**ACTIVITY NO.7** | **Performing _Face_Recognition**\n",
        "**Name** | Quibral, Juliann Vincent\n",
        "**Section** | CPE32S3\n",
        "**Date Performed**: | 2/21/2025\n",
        "**Date Submitted**: | 2/21/2025\n",
        "**Instructor**: | Engr. Roman M. Richard\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElMxAUPJGYLw"
      },
      "source": [
        "## 1. Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr0bUEs1nxE0"
      },
      "source": [
        "This activity aims to enable students to perform data preparation and face recognition on their own generated dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do-8nSpXFpyd"
      },
      "source": [
        "## 2. Intended Learning Outcomes (ILOs)\n",
        "After this activity, the students should be able to:\n",
        "* Utilize data preparation techniques for images.\n",
        "* Perform Face Recognition using multiple algorithms.\n",
        "* Evaluate the performance of different algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-RNZovNGV9k"
      },
      "source": [
        "## 3. Procedures and Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBQh8Eyf1EHC"
      },
      "source": [
        "### Preparing the training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpAAiS_V1Jfy"
      },
      "source": [
        "Now that we have our data, we need to load these sample pictures into our face recognition algorithms. All face recognition algorithms take two parameters in their `train()` method: an array of images and an array of labels. What do these labels represent? They are the IDs of a certain individual/face so that when face recognition is performed, we not only know the person was recognized but also who—among the many people available in our database—the person is.\n",
        "\n",
        "To do that, we need to create a comma-separated value (CSV) file, which will contain the path to a sample picture followed by the ID of that person."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWqIq9Sz1Svi"
      },
      "source": [
        "**Include a Screenshot of Your Dataset Here**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SiR2yJQ1W7B"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPA3SGHN1YdC"
      },
      "source": [
        "### Loading the data and recognizing faces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q07mfdMq1b2J"
      },
      "source": [
        "Next up, we need to load these two resources (the array of images and CSV file) into the face recognition algorithm, so it can be trained to recognize our face. To do this, we build a function that reads the CSV file and—for each line of the file—loads the image at the corresponding path into the images array and the ID into the labels array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c4TmUw_BEeUc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import errno\n",
        "import sys\n",
        "import cv2\n",
        "\n",
        "def read_images(path, sz=None):\n",
        "  c = 0\n",
        "  X, y = [], []\n",
        "\n",
        "  for dirname, dirnames, filenames in os.walk(path):\n",
        "    for subdirname in dirnames:\n",
        "      subject_path = os.path.join(dirname, subdirname)\n",
        "      for filename in os.listdir(subject_path):\n",
        "        try:\n",
        "          if(filename == \".directory\"):\n",
        "            continue\n",
        "          filepath = os.path.join(subject_path, filename)\n",
        "          im = cv2.imread(os.path.join(subject_path, filename), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "          # Resize the images to the prescribed size\n",
        "          if (sz is not None):\n",
        "            im = cv2.resize(im, (200,200))\n",
        "\n",
        "          X.append(np.asarray(im, dtype=np.uint8))\n",
        "          y.append(c)\n",
        "\n",
        "        except IOError as e:\n",
        "          print(f\"I/O Error({e.errno}): {e.strerror}\")\n",
        "        except:\n",
        "          print(\"Unexpected error:\", sys.exc_info()[0])\n",
        "          raise\n",
        "      c = c+1\n",
        "  return [X, y]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWNBxCbO2oO-"
      },
      "source": [
        "**Question: Run the function above on your generated dataset. Provide an analysis and note all the challenges you have encountered running this code.**\n",
        "\n",
        "I first encountered a number of directory-related problems when executing the function on the created dataset.  The script's directory paths did not match my local directory structure, which is why the code kept failing.  When the script tried to access or save files, this resulted in problems.  Nevertheless, the function operated as planned once I modified the paths to fit my local context.  The primary lesson here is how crucial it is to make sure that file paths are set up appropriately in order to prevent such problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ5IMZcC3wZt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlLWfyvY3xm0"
      },
      "source": [
        "### Performing Face Recognition Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVF9dfTQ30pc"
      },
      "source": [
        "Here is a sample script for testing the Face Recognition Algorithm. In this section, we're going to follow the same process but with different algorithms for face recognitions, namely:\n",
        "- Eigenface Recognition\n",
        "- Fisherface Recognition\n",
        "- Local Binary Pattern Histograms (LBPH) Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cYQ19foI4Oe7"
      },
      "outputs": [
        {
          "ename": "error",
          "evalue": "OpenCV(4.11.0) D:\\bld\\libopencv_1739279475736\\work\\opencv_contrib\\modules\\face\\src\\eigen_faces.cpp:62: error: (-5:Bad argument) Empty training data was given. You'll need more than one sample to learn a model. in function 'cv::face::Eigenfaces::train'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m   cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 47\u001b[0m   \u001b[43mface_rec\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[9], line 15\u001b[0m, in \u001b[0;36mface_rec\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mface\u001b[38;5;241m.\u001b[39mEigenFaceRecognizer_create()\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m camera \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     18\u001b[0m face_cascade \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCascadeClassifier(cv2\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mhaarcascades \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhaarcascade_frontalface_default.xml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\bld\\libopencv_1739279475736\\work\\opencv_contrib\\modules\\face\\src\\eigen_faces.cpp:62: error: (-5:Bad argument) Empty training data was given. You'll need more than one sample to learn a model. in function 'cv::face::Eigenfaces::train'\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def face_rec():\n",
        "  names = ['Friend1', 'Friend2'] # Put your names here for faces to recognize\n",
        "  if len(sys.argv) < 2:\n",
        "    print(\"USAGE: facerec_demo.py </path/to/images> [</path/to/store/images/at>]\")\n",
        "    sys.exit()\n",
        "\n",
        "  [X, y] = read_images(sys.argv[1])\n",
        "  y = np.asarray(y, dtype=np.int32)\n",
        "\n",
        "  model = cv2.face.EigenFaceRecognizer_create()\n",
        "  model.train(X, y)\n",
        "\n",
        "  camera = cv2.VideoCapture(0)\n",
        "  face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "  while True:\n",
        "    ret, img = camera.read()\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "      cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "      gray = cv2.cvtColor(img[y:y + h, x:x + w], cv2.COLOR_BGR2GRAY)\n",
        "      roi = cv2.resize(gray, (200, 200), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "      try:\n",
        "        params = model.predict(roi)\n",
        "        label = names[params[0]]\n",
        "        cv2.putText(img, label + \", \" + str(params[1]), (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "    cv2.imshow(\"camera\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "      break\n",
        "\n",
        "  camera.release()\n",
        "  cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  face_rec()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iChhyN_Y4OH7"
      },
      "source": [
        "**Question: Provide an analysis of the sample script for the process using the Eigenface Model. What is the sample code doing? Are you able to troubleshoot any problems encountered?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Principal Component Analysis (PCA) is used in the Eigenface Model sample script to do facial recognition.  By decreasing the dimensionality of facial images to a collection of \"eigenfaces,\" it is possible to recognize or validate faces.  Usually, the script loads a dataset of face photos, preprocesses them (e.g., resizes, converts to grayscale), trains the model, and then uses the model to identify or predict faces.\n",
        "\n",
        "I also ran across problems with the OpenCV library and its dependencies during this exercise, like \"cv2 has no face\" and \"cv2 has no data.\"  After doing some investigation, I discovered that my environment rather than the code was the issue.  The issues were caused by the script's directory structure not matching my local setup.  By changing the paths to match my local directory, this was fixed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dL7n-mc5JO6"
      },
      "source": [
        "---\n",
        "Perform the remaining face recognition techniques by using the same (or modified) process from the sample code:\n",
        "\n",
        "- `model = cv2.face.createFisherFaceRecognizer()`\n",
        "- `model = cv2.face.createLBPHFaceRecognizer()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb6Zeh9S5Y1o"
      },
      "source": [
        "**Question: The `predict()` method returns a two-element array. Provide your analysis of the two returned values and their important ince this application.**\n",
        "\n",
        "The Eigenface Model's predict() function yields a two-element array.  The predicted label or class (such as the identification of the person in the picture) is usually represented by the first element, while the prediction's confidence level or distance metric is shown by the second element.  Because it aids in assessing the prediction's dependability, the confidence level is essential.  While a greater number implies uncertainty or a possible mismatch, a lesser distance measure typically indicates a higher level of confidence in the prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkyd0KjtGl79"
      },
      "source": [
        "## 4. Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgo4nuQt506X"
      },
      "source": [
        "Your accomplisment of the tasks below contribute to the achievement of ILO1, ILO2, and ILO3 for this module.\n",
        "\n",
        "---\n",
        "\n",
        "Tasks:\n",
        "1. Create a new dataset for testing, this dataset must include the following:\n",
        "  - The same person/s that the model has to recognize.\n",
        "  - Different person/s that the model should not recognize.\n",
        "2. For each model, perform 20 tests. Document the testing performed and provide observations.\n",
        "3. Conclude on the performed tests by providing your evaluation of the performance of the models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "facerec_train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def load_images_from_folder(folder_path):\n",
        "    X, y = [], []\n",
        "    label_dict = {}\n",
        "    label_id = 0\n",
        "\n",
        "    for person_name in os.listdir(folder_path):\n",
        "        person_path = os.path.join(folder_path, person_name)\n",
        "        if not os.path.isdir(person_path):\n",
        "            continue\n",
        "        \n",
        "        if person_name not in label_dict:\n",
        "            label_dict[person_name] = label_id\n",
        "            label_id += 1\n",
        "\n",
        "        for image_name in os.listdir(person_path):\n",
        "            image_path = os.path.join(person_path, image_name)\n",
        "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                continue\n",
        "            img = cv2.resize(img, (200, 200))\n",
        "            X.append(img)\n",
        "            y.append(label_dict[person_name])\n",
        "    \n",
        "    return X, np.array(y), label_dict\n",
        "\n",
        "# Load training data\n",
        "train_path = \"images_train\"\n",
        "X_train, y_train, label_dict = load_images_from_folder(train_path)\n",
        "\n",
        "# Train the LBPH Face Recognizer\n",
        "model = cv2.face.LBPHFaceRecognizer_create()\n",
        "model.train(X_train, y_train)\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"face_model.yml\")\n",
        "np.save(\"label_dict.npy\", label_dict)\n",
        "print(\"Model trained and saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "facerec_test.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load trained model\n",
        "model = cv2.face.LBPHFaceRecognizer_create()\n",
        "model.read(\"face_model.yml\")\n",
        "label_dict = np.load(\"label_dict.npy\", allow_pickle=True).item()\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "\n",
        "# Testing dataset\n",
        "test_path = \"images_test\"\n",
        "correct_recognitions = 0\n",
        "total_tests = 0\n",
        "\n",
        "for person_name in os.listdir(test_path):\n",
        "    person_path = os.path.join(test_path, person_name)\n",
        "    if not os.path.isdir(person_path):\n",
        "        continue\n",
        "    \n",
        "    for image_name in os.listdir(person_path):\n",
        "        image_path = os.path.join(person_path, image_name)\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            continue\n",
        "        img = cv2.resize(img, (200, 200))\n",
        "\n",
        "        predicted_label, confidence = model.predict(img)\n",
        "        predicted_name = [name for name, label in label_dict.items() if label == predicted_label][0]\n",
        "\n",
        "        if person_name == predicted_name:\n",
        "            correct_recognitions += 1\n",
        "        \n",
        "        total_tests += 1\n",
        "        print(f\"Test Image: {image_name}, Actual: {person_name}, Predicted: {predicted_name}, Confidence: {confidence:.2f}\")\n",
        "\n",
        "accuracy = (correct_recognitions / total_tests) * 100\n",
        "print(f\"\\nFinal Accuracy: {accuracy:.2f}% ({correct_recognitions}/{total_tests} correct recognitions)\")\n",
        "\n",
        "# Real-time face recognition\n",
        "camera = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret, img = camera.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        face_roi = gray[y:y+h, x:x+w]\n",
        "        face_roi = cv2.resize(face_roi, (200, 200))\n",
        "\n",
        "        predicted_label, confidence = model.predict(face_roi)\n",
        "        predicted_name = [name for name, label in label_dict.items() if label == predicted_label][0]\n",
        "\n",
        "        cv2.putText(img, f\"{predicted_name}, {confidence:.2f}\", (x, y - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "\n",
        "    cv2.imshow(\"Face Recognition\", img)\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "camera.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQspxP0IGoO1"
      },
      "source": [
        "## 5. Summary, Conclusions and Lessons Learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvcmGICAoj1a"
      },
      "source": [
        "**Summary / Conclusion**\n",
        "\n",
        "I had difficulties with directory directories and OpenCV dependencies while building the Eigenface Model for facial recognition in this exercise.  The software creates eigenfaces for predictions by applying PCA to facial image processing.  I got errors like \"cv2 has no face\" and \"cv2 has no data\" because the directory structure of the script didn't match my local environment.  I fixed issues by modifying file locations and making sure everything was set up correctly after troubleshooting.  A two-element array containing the predicted label and a confidence metric—which is essential for assessing prediction reliability—was returned by the predict() method.  This experience made it clear how crucial it is to comprehend model results and match directory structures with the current environment.  The most important lesson is to confirm environment configuration and pathways prior to executing code in order to prevent problems and ensure smooth executaion.\n",
        "\n",
        "\n",
        "\n",
        "**Lesson Learned**\n",
        "The noted part of my takeaways is how crucial it is to make sure the environment and directory structures are set up properly before executing code.  Interpreting and evaluating the outcomes of machine learning models also requires a comprehension of the output of functions like predict().  This experience made it clear that using other libraries and datasets requires careful troubleshooting and flexibility.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqlVIPSqolAC"
      },
      "source": [
        "<hr/>\n",
        "\n",
        "***Proprietary Clause***\n",
        "\n",
        "*Property of the Technological Institute of the Philippines (T.I.P.). No part of the materials made and uploaded in this learning management system by T.I.P. may be copied, photographed, printed, reproduced, shared, transmitted, translated, or reduced to any electronic medium or machine-readable form, in whole or in part, without the prior consent of T.I.P.*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ElMxAUPJGYLw",
        "X-RNZovNGV9k",
        "Mkyd0KjtGl79",
        "KQspxP0IGoO1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "opencv_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
